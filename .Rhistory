data.table::as.data.table()
yeay$model$predict(tokenizer$encode(test$comment_text[1],max_length = max_len,
truncation=T, padding = 'max_length'))
data_prep = function(data) {
for (i in 1:nrow(data)) {
txt = tokenizer$encode(data[['comment_text']][i],max_length = max_len,
truncation=T, padding = 'max_length') %>%
t() %>%
as.matrix() %>% list()
text = text %>% append(txt)
}
list(do.call(plyr::rbind.fill.matrix,text))
}
testing_ = data_prep(test)
pred <- yeay$model$predict(testing_[[1]])
pred_df <- as.data.frame(pred)
pred_ls <- apply(pred_df,1,function(x) which(x==max(x)))
final_pred_df <- as.data.frame(pred_ls)
final_pred_df$id <- test$id
final_pred_df <-  final_pred_df %>% select(id, pred_ls) %>% rename(sentiment = pred_ls)
write.csv(final_pred_df, "./predict/roberta-2.csv", row.names = FALSE)
reticulate::py_install('transformers', pip = TRUE)
# library(tidyverse)
# library(textclean)
library(keras)
library(tensorflow)
library(dplyr)
library(tfdatasets)
transformer = reticulate::import('transformers')
physical_devices = tf$config$list_physical_devices('GPU')
tf$config$experimental$set_memory_growth(physical_devices[[1]],TRUE)
tf$keras$backend$set_floatx('float32')
df <- read.csv("./data/train.csv")
df = df %>% mutate(sentiment = sentiment - 1) %>%  rename(target = sentiment, comment_text = tweet) %>%
data.table::as.data.table()
idx_train = sample.int(nrow(df)*0.8)
train = df[idx_train,]
test = df[!idx_train,]
max_len = 50L
epochs = 2
batch_size = 64
tokenizer = transformer$AutoTokenizer$from_pretrained('roberta-base', do_lower_case=T)
# inputs
text = list()
# outputs
label = list()
data_prep = function(data) {
for (i in 1:nrow(data)) {
txt = tokenizer$encode(data[['comment_text']][i],max_length = max_len,
truncation=T, padding = 'max_length') %>%
t() %>%
as.matrix() %>% list()
lbl = data[['target']][i] %>% t()
text = text %>% append(txt)
label = label %>% append(lbl)
}
list(do.call(plyr::rbind.fill.matrix,text), do.call(plyr::rbind.fill.matrix,label))
}
train_ = data_prep(train)
test_ = data_prep(test)
# slice dataset
tf_train = tensor_slices_dataset(list(train_[[1]],train_[[2]])) %>%
dataset_batch(batch_size = batch_size, drop_remainder = TRUE) %>%
dataset_shuffle(128) %>% dataset_repeat(epochs)
tf_test = tensor_slices_dataset(list(test_[[1]],test_[[2]])) %>%
dataset_batch(batch_size = batch_size)
model_ = transformer$TFRobertaModel$from_pretrained('roberta-base')
# create an input layer
input = layer_input(shape=c(max_len), dtype='int32')
hidden_mean = tf$reduce_mean(model_(input)[[1]], axis=1L) %>%
layer_dense(128,activation = 'relu')
# create an output layer for binary classification
output = hidden_mean %>% layer_dense(64,activation = 'relu') %>% layer_dense(units = 3, activation='softmax')
model = keras_model(inputs=input, outputs = output)
# compile with AUC score
model %>% compile(optimizer= tf$keras$optimizers$Adam(learning_rate=1e-5, epsilon=1e-08, clipnorm=1.0),
loss = tf$losses$SparseCategoricalCrossentropy(from_logits=F),
metrics = 'accuracy')
# model = transformer$TFRobertaForMultipleChoice$from_pretrained('roberta-base', labels = c(1, 2, 3))
#
# model %>% compile(optimizer= tf$keras$optimizers$Adam(learning_rate=3e-5, epsilon=1e-08, clipnorm=1.0),
#                   loss = tf$losses$SparseCategoricalCrossentropy(from_logits=F),
#                   metrics = 'accuracy')
yeay=model$fit(tf_train, validation_data=tf_test, epochs=2L)
reticulate::py_install('transformers', pip = TRUE)
# library(tidyverse)
# library(textclean)
library(keras)
library(tensorflow)
library(dplyr)
library(tfdatasets)
transformer = reticulate::import('transformers')
physical_devices = tf$config$list_physical_devices('GPU')
tf$config$experimental$set_memory_growth(physical_devices[[1]],TRUE)
tf$keras$backend$set_floatx('float32')
df <- read.csv("./data/train.csv")
df = df %>% mutate(sentiment = sentiment - 1) %>%  rename(target = sentiment, comment_text = tweet) %>%
data.table::as.data.table()
idx_train = sample.int(nrow(df)*0.8)
train = df[idx_train,]
test = df[!idx_train,]
max_len = 50L
epochs = 2
batch_size = 32
tokenizer = transformer$AutoTokenizer$from_pretrained('roberta-base', do_lower_case=T)
# inputs
text = list()
# outputs
label = list()
data_prep = function(data) {
for (i in 1:nrow(data)) {
txt = tokenizer$encode(data[['comment_text']][i],max_length = max_len,
truncation=T, padding = 'max_length') %>%
t() %>%
as.matrix() %>% list()
lbl = data[['target']][i] %>% t()
text = text %>% append(txt)
label = label %>% append(lbl)
}
list(do.call(plyr::rbind.fill.matrix,text), do.call(plyr::rbind.fill.matrix,label))
}
train_ = data_prep(train)
test_ = data_prep(test)
# slice dataset
tf_train = tensor_slices_dataset(list(train_[[1]],train_[[2]])) %>%
dataset_batch(batch_size = batch_size, drop_remainder = TRUE) %>%
dataset_shuffle(128) %>% dataset_repeat(epochs)
tf_test = tensor_slices_dataset(list(test_[[1]],test_[[2]])) %>%
dataset_batch(batch_size = batch_size)
model_ = transformer$TFRobertaModel$from_pretrained('roberta-base')
# create an input layer
input = layer_input(shape=c(max_len), dtype='int32')
hidden_mean = tf$reduce_mean(model_(input)[[1]], axis=1L) %>%
layer_dense(128,activation = 'relu')
# create an output layer for binary classification
output = hidden_mean %>% layer_dense(64,activation = 'relu') %>% layer_dense(units = 3, activation='softmax')
model = keras_model(inputs=input, outputs = output)
# compile with AUC score
model %>% compile(optimizer= tf$keras$optimizers$Adam(learning_rate=1e-5, epsilon=1e-08, clipnorm=1.0),
loss = tf$losses$SparseCategoricalCrossentropy(from_logits=F),
metrics = 'accuracy')
# model = transformer$TFRobertaForMultipleChoice$from_pretrained('roberta-base', labels = c(1, 2, 3))
#
# model %>% compile(optimizer= tf$keras$optimizers$Adam(learning_rate=3e-5, epsilon=1e-08, clipnorm=1.0),
#                   loss = tf$losses$SparseCategoricalCrossentropy(from_logits=F),
#                   metrics = 'accuracy')
yeay=model$fit(tf_train, validation_data=tf_test, epochs=2L)
yeay$model$save("roberta-tweets-3")
test <- read.csv("./data/test.csv")
test = test %>% rename(comment_text = tweet) %>%
data.table::as.data.table()
data_prep = function(data) {
for (i in 1:nrow(data)) {
txt = tokenizer$encode(data[['comment_text']][i],max_length = max_len,
truncation=T, padding = 'max_length') %>%
t() %>%
as.matrix() %>% list()
text = text %>% append(txt)
}
list(do.call(plyr::rbind.fill.matrix,text))
}
testing_ = data_prep(test)
pred <- yeay$model$predict(testing_[[1]])
pred_df <- as.data.frame(pred)
pred_ls <- apply(pred_df,1,function(x) which(x==max(x)))
final_pred_df <- as.data.frame(pred_ls)
final_pred_df$id <- test$id
final_pred_df <-  final_pred_df %>% select(id, pred_ls) %>% rename(sentiment = pred_ls)
write.csv(final_pred_df, "./predict/roberta-3.csv", row.names = FALSE)
View(pred)
reticulate::py_install('transformers', pip = TRUE)
transformer = reticulate::import('transformers')
# library(tidyverse)
# library(textclean)
library(keras)
library(tensorflow)
library(dplyr)
library(tfdatasets)
install_tensorflow()
install_tensorflow()
# library(tidyverse)
# library(textclean)
library(keras)
install_tensorflow()
library(tensorflow)
install_tensorflow()
library(reticulate)
use_python("C:\Users\vinle\miniconda3\envs\r-reticulate")
use_python("C:\\Users\\vinle\\miniconda3\\envs\\r-reticulate")
library(reticulate)
library(reticulate)
# library(tidyverse)
# library(textclean)
library(keras)
library(tensorflow)
library(dplyr)
library(tfdatasets)
reticulate::virtualenv_create("r-reticulate")
reticulate::py_install('transformers', pip = TRUE)
reticulate::use_virtualenv("r-reticulate")
reticulate::py_install('transformers', pip = TRUE)
reticulate::py_install('transformers')
library(reticulate)
# library(tidyverse)
# library(textclean)
library(keras)
library(tensorflow)
library(dplyr)
library(tfdatasets)
reticulate::virtualenv_create("r-reticulate")
reticulate::use_virtualenv("r-reticulate")
reticulate::py_install('transformers')
reticulate::use_condaenv("r-reticulate")
reticulate::py_install('transformers')
library(reticulate)
library(reticulate)
# library(tidyverse)
# library(textclean)
library(keras)
library(tensorflow)
library(dplyr)
library(tfdatasets)
reticulate::virtualenv_create("r-reticulate")
reticulate::py_install('transformers')
reticulate::py_install('transformers', pip = TRUE)
reticulate::py_install('pip')
library(reticulate)
library(reticulate)
# library(tidyverse)
# library(textclean)
library(keras)
library(tensorflow)
library(dplyr)
library(tfdatasets)
reticulate::py_install('transformers', pip = TRUE)
reticulate::py_install('transformers')
library(reticulate)
# library(tidyverse)
# library(textclean)
library(keras)
library(tensorflow)
library(dplyr)
library(tfdatasets)
reticulate::py_install('transformers', pip = T)
library(reticulate)
# library(tidyverse)
# library(textclean)
library(keras)
library(tensorflow)
library(dplyr)
library(tfdatasets)
reticulate::use_python("C:\\Users\\vinle\\miniconda3\\envs\\r-transformers")
transformer = reticulate::import('transformers')
reticulate::py_install('transformers', pip = T)
library(reticulate)
# library(tidyverse)
# library(textclean)
library(keras)
library(tensorflow)
library(dplyr)
library(tfdatasets)
reticulate::use_python("C:\\Users\\vinle\\miniconda3\\envs\\r-transformers")
reticulate::use_python("C:\\Users\\vinle\\miniconda3\\envs\\r-transformers", required = T)
reticulate::use_python("C:\\Users\\vinle\\miniconda3\\envs\\transformers", required = T)
library(reticulate)
# library(tidyverse)
# library(textclean)
library(keras)
library(tensorflow)
library(dplyr)
library(tfdatasets)
reticulate::use_python("C:\\Users\\vinle\\miniconda3\\envs\\transformers", required = T)
Sys.setenv(RETICULATE_PYTHON = "C:\\Users\\vinle\\miniconda3\\envs\\transformers")
RETICULATE_PYTHON="C:\\Users\\vinle\\miniconda3\\envs\\transformers"
library(reticulate)
library(reticulate)
# library(tidyverse)
# library(textclean)
library(keras)
library(tensorflow)
library(dplyr)
library(tfdatasets)
reticulate::use_python("C:\\Users\\vinle\\miniconda3\\envs\\transformers", required = T)
reticulate::py_install('transformers', pip = T)
transformer = reticulate::import('transformers')
Sys.setenv(RETICULATE_PYTHON = "C:\\Users\\vinle\\miniconda3\\envs\\transformers")
RETICULATE_PYTHON="C:\\Users\\vinle\\miniconda3\\envs\\transformers"
library(reticulate)
library(reticulate)
# library(tidyverse)
# library(textclean)
library(keras)
library(tensorflow)
library(dplyr)
library(tfdatasets)
reticulate::use_python("C:\\Users\\vinle\\miniconda3\\envs\\transformers", required = T)
reticulate::py_install('transformers', pip = T)
transformer = reticulate::import('transformers')
Sys.setenv(RETICULATE_PYTHON = "C:\\Users\\vinle\\miniconda3\\envs\\transformers\\python")
RETICULATE_PYTHON="C:\\Users\\vinle\\miniconda3\\envs\\transformers\\python"
library(reticulate)
library(reticulate)
# library(tidyverse)
# library(textclean)
library(keras)
library(tensorflow)
library(dplyr)
library(tfdatasets)
reticulate::py_install('transformers', pip = T)
transformer = reticulate::import('transformers')
reticulate::use_python("C:\\Users\\vinle\\miniconda3\\envs\\transformers\\python", required = T)
reticulate::use_python("C:\\Users\\vinle\\miniconda3\\envs\\transformers", required = T)
reticulate::py_install('transformers', pip = T)
transformer = reticulate::import('transformers')
# GPU optimisation. Comment if using CPU.
physical_devices = tf$config$list_physical_devices('GPU')
tf$config$experimental$set_memory_growth(physical_devices[[1]],TRUE)
tf$keras$backend$set_floatx('float32')
reticulate::use_python("C:\\Users\\vinle\\miniconda3\\envs\\transformers", required = T)
reticulate::use_python("C:\\Users\\vinle\\miniconda3\\envs\\transformers", required = T)
reticulate::use_python("C:\\Users\\vinle\\miniconda3\\envs\\transformers", required = T)
reticulate::use_python("C:\\Users\\vinle\\miniconda3\\envs\\transformers", required = T)
reticulate::use_python("C:\\Users\\vinle\\miniconda3\\envs\\transformers", required = T)
usethis::edit_r_environ()
library(reticulate)
library(reticulate)
# library(tidyverse)
# library(textclean)
library(keras)
library(tensorflow)
library(dplyr)
library(tfdatasets)
reticulate::use_python("C:\\Users\\vinle\\miniconda3\\envs\\transformers", required = T)
reticulate::py_install('transformers', pip = T)
transformer = reticulate::import('transformers')
transformer = reticulate::import('transformers')
usethis::edit_r_environ()
library(reticulate)
# library(tidyverse)
# library(textclean)
library(keras)
library(tensorflow)
library(dplyr)
library(tfdatasets)
reticulate::py_install('transformers', pip = T)
transformer = reticulate::import('transformers')
# GPU optimisation. Comment if using CPU.
physical_devices = tf$config$list_physical_devices('GPU')
install_tensorflow()
?install_tensorflow()
library(reticulate)
# library(tidyverse)
# library(textclean)
library(tfdatasets)
reticulate::py_install('transformers', pip = T)
transformer = reticulate::import('transformers')
install_tensorflow()
library(reticulate)
# library(tidyverse)
# library(textclean)
library(tfdatasets)
reticulate::py_install('transformers', pip = T)
reticulate::py_install('transformers', pip = T)
install_tensorflow()
library(keras)
library(tensorflow)
library(dplyr)
tensorflow::install_tensorflow()
library(reticulate)
# library(tidyverse)
# library(textclean)
library(tfdatasets)
reticulate::py_install('tensorflow', pip = T)
reticulate::py_install('transformers', pip = T)
transformer = reticulate::import('transformers')
library(keras)
library(tensorflow)
library(dplyr)
# GPU optimisation. Comment if using CPU.
physical_devices = tf$config$list_physical_devices('GPU')
tf$config$experimental$set_memory_growth(physical_devices[[1]],TRUE)
tf$keras$backend$set_floatx('float32')
# GPU optimisation. Comment if using CPU.
physical_devices = tf$config$list_physical_devices('GPU')
tf$config$experimental$set_memory_growth(physical_devices[[1]],TRUE)
View(physical_devices)
library(reticulate)
reticulate::py_install('tensorflow', pip = TRUE)
reticulate::py_install('torch', pip = TRUE)
reticulate::py_install('transformers', pip = TRUE)
# library(tidyverse)
# library(textclean)
library(keras)
library(tensorflow)
library(dplyr)
library(tfdatasets)
transformer = reticulate::import('transformers')
# GPU optimisation. Comment if using CPU.
physical_devices = tf$config$list_physical_devices('GPU')
tf$config$experimental$set_memory_growth(physical_devices[[1]],TRUE)
tf$keras$backend$set_floatx('float32')
df = df %>% mutate(sentiment = sentiment - 1) %>%  rename(target = sentiment, comment_text = tweet) %>%
data.table::as.data.table()
df <- read.csv("./data/train.csv")
setwd("~/# Main/# SUTD/2021/tae-data-competition")
df <- read.csv("./data/train.csv")
df <- read.csv("/data/train.csv")
setwd("~/# Main/# SUTD/2021/tae-data-competition")
df <- read.csv("./data/train.csv")
df <- read.csv("./data/train.csv")
getwd()
library(tidyverse)
df <- read_csv("./data/train.csv")
df <- read.csv("../../data/train.csv")
df <- read.csv("../../data/train.csv") # DEPENDS ON RSTUDIO WORKING DIRECTORY CONFIG
df = df %>% mutate(sentiment = sentiment - 1) %>%  rename(target = sentiment, comment_text = tweet) %>%
data.table::as.data.table()
idx_train = sample.int(nrow(df)*0.8)
train = df[idx_train,]
test = df[!idx_train,]
max_len = 50L
epochs = 2
batch_size = 32
tokenizer = transformer$AutoTokenizer$from_pretrained('roberta-base', do_lower_case=T)
library(reticulate)
reticulate::py_install('tensorflow', pip = TRUE)
reticulate::py_install('torch', pip = TRUE)
reticulate::py_install('transformers', pip = TRUE)
# library(tidyverse)
# library(textclean)
library(keras)
library(tensorflow)
library(dplyr)
library(tfdatasets)
transformer = reticulate::import('transformers')
# GPU optimisation. Comment if using CPU.
physical_devices = tf$config$list_physical_devices('GPU')
tf$config$experimental$set_memory_growth(physical_devices[[1]],TRUE)
tf$keras$backend$set_floatx('float32')
max_len = 50L
epochs = 2
batch_size = 32
tokenizer = transformer$AutoTokenizer$from_pretrained('roberta-base', do_lower_case=T)
# inputs
text = list()
# outputs
label = list()
data_prep = function(data) {
for (i in 1:nrow(data)) {
txt = tokenizer$encode(data[['comment_text']][i],max_length = max_len,
truncation=T, padding = 'max_length') %>%
t() %>%
as.matrix() %>% list()
lbl = data[['target']][i] %>% t()
text = text %>% append(txt)
label = label %>% append(lbl)
}
list(do.call(plyr::rbind.fill.matrix,text), do.call(plyr::rbind.fill.matrix,label))
}
train_ = data_prep(train)
test_ = data_prep(test)
# slice dataset
tf_train = tensor_slices_dataset(list(train_[[1]],train_[[2]])) %>%
dataset_batch(batch_size = batch_size, drop_remainder = TRUE) %>%
dataset_shuffle(128) %>% dataset_repeat(epochs)
tf_test = tensor_slices_dataset(list(test_[[1]],test_[[2]])) %>%
dataset_batch(batch_size = batch_size)
model_ = transformer$TFRobertaModel$from_pretrained('roberta-base')
# create an input layer
input = layer_input(shape=c(max_len), dtype='int32')
hidden_mean = tf$reduce_mean(model_(input)[[1]], axis=1L) %>%
layer_dense(128,activation = 'relu')
# create an output layer for binary classification
output = hidden_mean %>% layer_dense(64,activation = 'relu') %>% layer_dense(units = 3, activation='softmax')
model = keras_model(inputs=input, outputs = output)
# compile with AUC score
model %>% compile(optimizer= tf$keras$optimizers$Adam(learning_rate=1e-5, epsilon=1e-08, clipnorm=1.0),
loss = tf$losses$SparseCategoricalCrossentropy(from_logits=F),
metrics = 'accuracy')
# model = transformer$TFRobertaForMultipleChoice$from_pretrained('roberta-base', labels = c(1, 2, 3))
#
# model %>% compile(optimizer= tf$keras$optimizers$Adam(learning_rate=3e-5, epsilon=1e-08, clipnorm=1.0),
#                   loss = tf$losses$SparseCategoricalCrossentropy(from_logits=F),
#                   metrics = 'accuracy')
yeay=model$fit(tf_train, validation_data=tf_test, epochs=2L)
yeay$model$save("roberta-tweets-3-2")
test = test %>% rename(comment_text = tweet) %>%
data.table::as.data.table()
test <- read.csv("../../data/test.csv") # DEPENDS ON RSTUDIO WORKING DIRECTORY CONFIG
test = test %>% rename(comment_text = tweet) %>%
data.table::as.data.table()
data_prep = function(data) {
for (i in 1:nrow(data)) {
txt = tokenizer$encode(data[['comment_text']][i],max_length = max_len,
truncation=T, padding = 'max_length') %>%
t() %>%
as.matrix() %>% list()
text = text %>% append(txt)
}
list(do.call(plyr::rbind.fill.matrix,text))
}
testing_ = data_prep(test)
pred <- yeay$model$predict(testing_[[1]])
pred_df <- as.data.frame(pred)
pred_ls <- apply(pred_df,1,function(x) which(x==max(x)))
final_pred_df <- as.data.frame(pred_ls)
final_pred_df$id <- test$id
final_pred_df <-  final_pred_df %>% select(id, pred_ls) %>% rename(sentiment = pred_ls)
write.csv(final_pred_df, "../../predict/roberta-3-2.csv", row.names = FALSE)
getwd()
write.csv(final_pred_df, "./predict/roberta-3-2.csv", row.names = FALSE)
write.csv(final_pred_df, "../../predict/roberta-3-2.csv", row.names = FALSE)
